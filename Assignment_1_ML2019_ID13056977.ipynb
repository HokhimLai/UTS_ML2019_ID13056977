{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1_ML2019_ID13056977.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HokhimLai/UTS_ML2019_ID13056977/blob/master/Assignment_1_ML2019_ID13056977.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLQ4zuPuQ95u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First line "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EngpWTofZC8W",
        "colab_type": "text"
      },
      "source": [
        "`Student ID: 13056977`    \n",
        "`Student name: HokHim Lai`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcJyEABMj0Q_",
        "colab_type": "text"
      },
      "source": [
        "Github reporsitory link: [link text](https://github.com/HokhimLai/UTS_ML2019_ID13056977)  \n",
        "\n",
        "https://github.com/HokhimLai/UTS_ML2019_ID13056977"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rduZaCh5X3B2",
        "colab_type": "text"
      },
      "source": [
        "#Assignmnt 1: Understanding the Literature\n",
        "\n",
        "##Topic: Generative Adversarial Nets , GOO14_GAN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81kr_kYIZZA1",
        "colab_type": "text"
      },
      "source": [
        "##1 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBjqKAOLR4yn",
        "colab_type": "text"
      },
      "source": [
        "Generative modelling is a new kind of machine learning model classification recently have been heavily developed and applied to the industry. It has been distinguished three major classes by Jebara at around 2004. They are generative learning, discriminative learning and conditional learning. When it comes to 2019, generative model already developed in a well progress and started being applied by technology companies such as DeepMind and NVIDIA for different purposes. It can apply in different areas, for example, super-resolution, colorization product or realistic samples for artwork.\n",
        " \n",
        "The idea of Generative Model is to give a training data to machine learn and define the real and fake data. In generative models, there are more than one type of models can be used in different circumstances. Among all of them, Fully Visible Belief, Variational Autoencoder and Generative adversarial networks (GAN) are the most popular type of class used in today. In the following report will mainly focus on review and critique <b>GAN</b> based on the GOO14_GAN report.\n",
        "\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PNpIXwKZbz1",
        "colab_type": "text"
      },
      "source": [
        "##2 Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgwY75yFtiO0",
        "colab_type": "text"
      },
      "source": [
        "This paper is about researcher trying to introduce a new framework for reckoning generative model via GAN. Researcher is going to set up two model to test out the effectiveness of the discriminative model. The final goal is to reach a high success rate on the generative data can fool discriminative model. This experiment will show the potential and possibility of the framework through the evaluation of the distinctive and  generated samples.\n",
        "\n",
        "Researchers have set up two main models in this test. One is a generative model *G*, a model that capture the data noise and distribution. Another one is a discriminative model *D*, use to estimate the probability that the sample comes from training data set or generative model. Training GAN is basically like two player game, *G* try to fool the discriminator by generating data that is similar to the training data. And *D* try to distinguish and identify the data is either real or from the generator. And the goal is finally the discriminator is unable to clarify and define the data is real or fake.\n",
        "\n",
        "__The equation of *D* & *G* two player game :__\n",
        "\n",
        "$min_G~max_D V(D,G) = E_{x-p_{data}(x)}[logD(x)]+ E_{z-p_z(z)}[log(1 - D(G(z)))]$\n",
        "\n",
        "In the experiment, research trained GAN a range of datasets including MNIST, the Toronto Face Database and CIFAR-10. \n",
        "Under is the Pazen window-based estimation of different model:\n",
        "\n",
        "Model | MNIST| TFD \n",
        "---|---|---\n",
        "DBN|138 ± 2 | 1909 ± 66\n",
        "Stacked CAE|121 ± 1.6|2110 ± 50\n",
        "Deep GSN | 214 ± 1.1 | 1890 ± 29\n",
        "GAN |__225 ± 2__ | __2057 ± 26__\n",
        "\n",
        "Through the table we can find that GAN have a higher success rate than other training model. GAN score 225 ± 2 on MINIST and 2057 ± 26 on TFD. Proved that GAN perform well on either MINIST or TFD dataset, and is the best method among 4 of the model. \n",
        "\n",
        "\n",
        "The report has shown us how the new framework perform. There are some advantages and disadvantages of this new framework. At the end of the paper, research has summarized the goods and drawbacks of this new modelling method. Here are some examples of what challenge they have faced. They found that when they try to train the GAN, it was synchronizing the discriminator with the generator, Helvetica.  Two model *G* and *D* have to train it in synchronized, it can’t just update one model without another one, otherwise, Helvetica problem will happen. Overall, researchers can indicate the framework clearly and detailty , including state the problem at the beginning, fully explain the function with graph and a summarized table of challenge at the end. When all these combined together can let read study it easily.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnsWs6VeFB6x",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBlq4YipZeTg",
        "colab_type": "text"
      },
      "source": [
        "##3 Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iJqd4P7HrAn",
        "colab_type": "text"
      },
      "source": [
        "In the report, researchers have stated out the model function and other algorithms. In the paper they have stated out the model function clearly with a full support of explain. For example, they mentioned that\n",
        "\n",
        "$E_{x-p_{data}(x)}[logD(x)]$: the fuction of discriminator output for real data x\n",
        "\n",
        "$E_{z-pz}(z)[log(1-D(G(z))]$: the fuction of discriminator output for generated fake data G(z)\n",
        "\n",
        "Discriminator output will be ethier (1,0) of real data. Discriminator want to maximzie the objective so that D(x) can close to 1 (real data) and D(G(z)) is close to 0 (fake data). On the other hand, the generator want to minimize objective so that D(G(z)) close to 1.\n",
        "\n",
        "We can see that they have thoroughly demonstrated how the algorithm operate and clarity the purpose and use of each part. Moreover, in order to let reviewer analyse the function deeply, they put function graph to demonstrate how the models work and compile each other. Therefore, researchers have totally display the innovation of the work. \n",
        "\n",
        "__Figure 1: Function graph__\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/HokhimLai/UTS_ML2019_ID13056977/blob/master/Fucntion%20Graph.png?raw=true\" width=\"600\"/>                                             \n",
        "  \n",
        "  \n",
        "On the other hand, the paper used an inventive way to show the comparison between the generative modeling. They created a table to explain the challenge and obstacle when they try to apply dataset to the model. In order to show a completeness analysis, they have used other generative modeling to compare with the main model, GAN.  In the summarized table, researchers compare GAN with other generative model not only one perspective, but in a full way. For example, in order to show the convenience of GAN, table showed  how accessible when it apply on sampling compared with other modeling. Generative autoencoders and Deep undirected graphical models are requires Markov chain, but GAN doesn’t need any requirements on sampling. Using the table not only show the challenges were faced of each generative modeling, it demonstrate the advantage and benefit of GAN when it compare to other model. This is an innovative way to show a comparison between models.\n",
        "\n",
        "__Here is the table of showing the comparison challenge between modeling:__\n",
        "<img src=\"https://github.com/HokhimLai/UTS_ML2019_ID13056977/blob/master/Table%20of%20modeling%20challenage.png?raw=true\" width=\"600\"/>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdvgev0dZl3j",
        "colab_type": "text"
      },
      "source": [
        "##4 Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozafNcnbXCks",
        "colab_type": "text"
      },
      "source": [
        "From my perspective, I would rate a moderate to high technical quality to this paper. For the algorithm of the model, paper show a high quality rate of the equation. The modeling equation can apply fittly into the dataset. Researcher showed how the two models *G* and *D*  interact with each other through the function equation. They also explained the model two player game long-windedly with using counterfeit currency as an example. Beyond the theorem part, paper also shown the full step of training GAN. Like for how many number of training iterations should do, and fully explained how the sample minibatch would affect the noise. Furthermore, paper have also consider different situations and give a correlated theorem to proof with other equation. For example, to Global Optimality of $p_g = p_data$, the paper list up other function to proof it. \n",
        "\n",
        "__Here is the equation of Global Optimality of $p_g = p_data$:__\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/HokhimLai/UTS_ML2019_ID13056977/blob/master/Equation%20for%20global%20optinmize.png?raw=true\" width=\"600\"/>   \n",
        "Paper also cover more than one theorem, for example, Jensen-Shannon divergence and the convergence of Algorithm 1. Here is the figure:\n",
        "For the testing dataset, moderate quality is given. In order to show how the model works in different circumstances, 3 dataset of data is used to train the model. It did prove that GAN did well on MNIST and TFD dataset, but it didn’t show the result of CIFAR-101, it can’t prove that GAN can work perfectly in 3 of the dataset. I not sure the reason of not showing the result of CIFAR-101, either is a mistake or bias, but based on the completeness report of the performance of GAN. Moderate technical quality rate is given. \n",
        "  \n",
        "__Here is the table of GAN performance on MNIST and TFD dataset:__\n",
        "\n",
        "  \n",
        "  \n",
        "  Model | MNIST| TFD \n",
        "---|---|---\n",
        "DBN|138 ± 2 | 1909 ± 66\n",
        "Stacked CAE|121 ± 1.6|2110 ± 50\n",
        "Deep GSN | 214 ± 1.1 | 1890 ± 29\n",
        "GAN |__225 ± 2__ | __2057 ± 26__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4TYNiYiZs6Q",
        "colab_type": "text"
      },
      "source": [
        "##5 Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEtoZNXHri9z",
        "colab_type": "text"
      },
      "source": [
        "The application domain is surprisingly suitable for GAN. Using image to test GAN network come up with a good result. The paper experiment took the image sample from the MNIST, CIFAR-10 and TFD dataset. The purpose new framework can function regularly with three dataset and perform in a good result. Therefore, using image to test out GAN is a good way to analyze the model. However, I think there are more possible type of data can fit into this frame and they are worth  to try no matter success or not. Refer to the research from Hong, Hwang, Yoo, and Yoon (_How Generative Adversarial Networks and Their Variants Work: An Overview_), there are other domain data can try.  For example some sequential data, music and text generation and speech conversion. Although these data cannot get the accuracy correction of data. But it invole in an innovation way use.  It would be a good example to show the potential of GAN if more one domain is included in the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1J9O519ajKN",
        "colab_type": "text"
      },
      "source": [
        "##6 Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHYD875trxwL",
        "colab_type": "text"
      },
      "source": [
        "In conclusion, the paper can purpose the new framework fully with the function of modeling and explain the potential through experiment. Especially in developing the function of modeling part, it shows a comprehensive work when it applied to other theory. At the last part of the paper, use a table to demonstrate the advantages and disadvantages of GAN comparing with other generative modeling. This can show the superiority side of GAN. With the detailed explanation of challenge in training GAN, it can provide a solution and example to researcher to avoid error execute. Overall, this paper can coverage all part of GAN and show the pros and cons of GAN. The final topic (__7 Conclusion and future work__) given a guide and sample to other researcher on the future work of GAN. The only thing have to critique is some part in the paper didn’t explain deep enough explanation. In the state of experiment, the paper didn’t show the progress of explainment, just briefly mention it and show the result. It would be good if the paper can cover the progress of GAN modeling with different dataset. Also, when using other generative method for comparison, it didn't show the result and progress when using other models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "genUwHRMazcf",
        "colab_type": "text"
      },
      "source": [
        "##7 References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h4jZItxjBdz",
        "colab_type": "text"
      },
      "source": [
        "Ian. G, Jean. A, Mehdi.M, Bing.X, David.W, Sherjil.O, Aaron.C & Yoshua.B. 2014, ‘Generative Adversarial Nets’ , Universite de Montreal\n",
        "\n",
        "\n",
        "Hong.Y, Uiwon.H, Jaeyoon.Y & Sungroh.Y, 2019, 'How Generative Adversarial Networks and Their Variants Work: An Overview’ , Seoul National University, Seoul, Korea \n",
        "\n",
        "\n",
        "Vasilev.I, 2019, 'Python Deep Learning - Second Edition’ , Packt Publishing, 2019\n",
        "\n",
        "\n",
        "Ganguly. K, 2019, 'Learning Generative Adversarial Networks’ , Packt Publishing, 2018, Safari, an O'Reilly Media Company\n",
        "\n",
        "\n",
        "Fangyu.C,Michael.S. 2019, ‘DeepMind Proposes a Novel Way to Improve GANs Using Gradient Information’, Synced\n",
        "<https://medium.com/syncedreview/deepmind-proposes-a-novel-way-to-improve-gans-using-gradient-information-3fc3610ac976>\n",
        "\n",
        "\n",
        "James.V. 2018, ‘These faces show how far AI image generation has advanced in just four years’, The Verge\n",
        "<https://www.theverge.com/2018/12/17/18144356/ai-image-generation-fake-faces-people-nvidia-generative-adversarial-networks-gans>"
      ]
    }
  ]
}